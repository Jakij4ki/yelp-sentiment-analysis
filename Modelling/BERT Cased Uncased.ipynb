{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13355381,"sourceType":"datasetVersion","datasetId":8470856}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library & Setup","metadata":{}},{"cell_type":"code","source":"!pip install -U \"transformers==4.40.2\" \"huggingface-hub==0.23.5\" -q\n\nimport os\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n\n# Matiin HuggingFace chat template warning (soalnya sempet ada error)\nos.environ[\"HF_HUB_DISABLE_CHAT_TEMPLATES\"] = \"1\"\n\n# Cek device sekarang\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:05:43.178972Z","iopub.execute_input":"2025-10-13T16:05:43.179200Z","iopub.status.idle":"2025-10-13T16:06:04.789698Z","shell.execute_reply.started":"2025-10-13T16:05:43.179174Z","shell.execute_reply":"2025-10-13T16:06:04.788863Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\ndiffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.5 which is incompatible.\npeft 0.16.0 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\ngradio 5.38.1 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.5 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mUsing device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/yelp-bert-dataset/data bert 2.parquet\")\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:04.790636Z","iopub.execute_input":"2025-10-13T16:06:04.791046Z","iopub.status.idle":"2025-10-13T16:06:05.696540Z","shell.execute_reply.started":"2025-10-13T16:06:04.791024Z","shell.execute_reply":"2025-10-13T16:06:05.695543Z"}},"outputs":[{"name":"stdout","text":"                                                text  sentiment\n0  If you decide to eat here, just be aware it is...          1\n1  A couple friends and I stopped by for some lat...          1\n2  Sometimes this food is very very good.  Unfort...          1\n3  After trying a few ramen places with crazy var...          1\n4  Great food. Terrible customer service. I've be...          1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df['sentiment'] = df['sentiment'].astype('category').cat.codes\n\n# Split train & validation set\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['text'].tolist(), df['sentiment'].tolist(), test_size=0.2, random_state=42\n)\n\nprint(f\"Total data: {len(df)} | Train: {len(train_texts)} | Validation: {len(val_texts)}\")\nprint(df['sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:05.698590Z","iopub.execute_input":"2025-10-13T16:06:05.698943Z","iopub.status.idle":"2025-10-13T16:06:05.745244Z","shell.execute_reply.started":"2025-10-13T16:06:05.698923Z","shell.execute_reply":"2025-10-13T16:06:05.744562Z"}},"outputs":[{"name":"stdout","text":"Total data: 60000 | Train: 48000 | Validation: 12000\nsentiment\n1    20000\n2    20000\n0    20000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Tokenizer Preparation (Cased & Uncased)","metadata":{}},{"cell_type":"code","source":"tokenizer_cased = BertTokenizer.from_pretrained('bert-base-cased')\ntokenizer_uncased = BertTokenizer.from_pretrained('bert-base-uncased')\n\nprint(\"Tokenizer loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:05.745996Z","iopub.execute_input":"2025-10-13T16:06:05.746217Z","iopub.status.idle":"2025-10-13T16:06:08.390499Z","shell.execute_reply.started":"2025-10-13T16:06:05.746201Z","shell.execute_reply":"2025-10-13T16:06:08.389679Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7e17cfcd7914fed8ddc772cedaa38aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e04d37e15a8e4d32b0567ee807b89935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b57d1334d77747b2a06ed02a38ca36c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bd30a581df946aba15398e8e70ab51f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea1046e095924bb892c746fae62900ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3fdcc6b44f54e6a95def35ed40af5dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"879547ee42b0422f974e262bd4557c9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c96c21b8fb0b4b28ac4f628847fb2c5f"}},"metadata":{}},{"name":"stdout","text":"Tokenizer loaded successfully!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Dataset & DataLoader","metadata":{}},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=256):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        sentiment = self.labels[idx]\n        enc = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': enc['input_ids'].flatten(),\n            'attention_mask': enc['attention_mask'].flatten(),\n            'labels': torch.tensor(sentiment, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:08.391397Z","iopub.execute_input":"2025-10-13T16:06:08.391986Z","iopub.status.idle":"2025-10-13T16:06:08.397033Z","shell.execute_reply.started":"2025-10-13T16:06:08.391960Z","shell.execute_reply":"2025-10-13T16:06:08.396301Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_data_cased = TextDataset(train_texts, train_labels, tokenizer_cased)\nval_data_cased = TextDataset(val_texts, val_labels, tokenizer_cased)\ntrain_data_uncased = TextDataset(train_texts, train_labels, tokenizer_uncased)\nval_data_uncased = TextDataset(val_texts, val_labels, tokenizer_uncased)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:08.397821Z","iopub.execute_input":"2025-10-13T16:06:08.398060Z","iopub.status.idle":"2025-10-13T16:06:08.446275Z","shell.execute_reply.started":"2025-10-13T16:06:08.398044Z","shell.execute_reply":"2025-10-13T16:06:08.445513Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# DataLoader\ntrain_loader_cased = DataLoader(train_data_cased, batch_size=32, shuffle=True)\nval_loader_cased = DataLoader(val_data_cased, batch_size=32, shuffle=False)\ntrain_loader_uncased = DataLoader(train_data_uncased, batch_size=32, shuffle=True)\nval_loader_uncased = DataLoader(val_data_uncased, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:08.447025Z","iopub.execute_input":"2025-10-13T16:06:08.447252Z","iopub.status.idle":"2025-10-13T16:06:08.460667Z","shell.execute_reply.started":"2025-10-13T16:06:08.447226Z","shell.execute_reply":"2025-10-13T16:06:08.459983Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Model Initialization (BERT Cased & Uncased)","metadata":{}},{"cell_type":"code","source":"# BERT Cased\nmodel_cased = BertForSequenceClassification.from_pretrained(\n    'bert-base-cased', num_labels=len(set(df['sentiment']))\n).to(device)\n\noptimizer_cased = AdamW(model_cased.parameters(), lr=3e-5)\nscheduler_cased = get_linear_schedule_with_warmup(\n    optimizer_cased, num_warmup_steps=0, num_training_steps=len(train_loader_cased)*3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:08.461497Z","iopub.execute_input":"2025-10-13T16:06:08.461793Z","iopub.status.idle":"2025-10-13T16:06:13.061908Z","shell.execute_reply.started":"2025-10-13T16:06:08.461768Z","shell.execute_reply":"2025-10-13T16:06:13.061301Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af8fb94b5c0b4f6cabcef7720aa12c9c"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# BERT Uncased\nmodel_uncased = BertForSequenceClassification.from_pretrained(\n    'bert-base-uncased', num_labels=len(set(df['sentiment']))\n).to(device)\n\noptimizer_uncased = AdamW(model_uncased.parameters(), lr=3e-5)\nscheduler_uncased = get_linear_schedule_with_warmup(\n    optimizer_uncased, num_warmup_steps=0, num_training_steps=len(train_loader_uncased)*3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:13.063694Z","iopub.execute_input":"2025-10-13T16:06:13.063992Z","iopub.status.idle":"2025-10-13T16:06:15.268217Z","shell.execute_reply.started":"2025-10-13T16:06:13.063974Z","shell.execute_reply":"2025-10-13T16:06:15.267561Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b78b556a9ded454ab12b312b4520d479"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Training Loops","metadata":{}},{"cell_type":"code","source":"epochs = 5\n\n# BERT Cased\nfor epoch in range(epochs):\n    model_cased.train()\n    total_loss = 0\n    for batch in tqdm(train_loader_cased, desc=f\"[Cased] Epoch {epoch+1}\"):\n        optimizer_cased.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model_cased(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer_cased.step()\n        scheduler_cased.step()\n\n    print(f\"[Cased] Epoch {epoch+1} | Loss: {total_loss/len(train_loader_cased):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-13T16:06:15.268901Z","iopub.execute_input":"2025-10-13T16:06:15.269092Z","iopub.status.idle":"2025-10-13T17:40:39.123396Z","shell.execute_reply.started":"2025-10-13T16:06:15.269077Z","shell.execute_reply":"2025-10-13T17:40:39.122685Z"}},"outputs":[{"name":"stderr","text":"[Cased] Epoch 1: 100%|██████████| 1500/1500 [18:49<00:00,  1.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 1 | Loss: 0.5233\n","output_type":"stream"},{"name":"stderr","text":"[Cased] Epoch 2: 100%|██████████| 1500/1500 [18:52<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 2 | Loss: 0.3672\n","output_type":"stream"},{"name":"stderr","text":"[Cased] Epoch 3: 100%|██████████| 1500/1500 [18:53<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 3 | Loss: 0.2279\n","output_type":"stream"},{"name":"stderr","text":"[Cased] Epoch 4: 100%|██████████| 1500/1500 [18:53<00:00,  1.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 4 | Loss: 0.1654\n","output_type":"stream"},{"name":"stderr","text":"[Cased] Epoch 5: 100%|██████████| 1500/1500 [18:54<00:00,  1.32it/s]","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 5 | Loss: 0.1650\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# BERT Uncased\nfor epoch in range(epochs):\n    model_uncased.train()\n    total_loss = 0\n    for batch in tqdm(train_loader_uncased, desc=f\"[Uncased] Epoch {epoch+1}\"):\n        optimizer_uncased.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model_uncased(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer_uncased.step()\n        scheduler_uncased.step()\n\n    print(f\"[Uncased] Epoch {epoch+1} | Loss: {total_loss/len(train_loader_uncased):.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-13T18:19:21.057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate(model, loader, name=\"Model\"):\n    model.eval()\n    preds, actuals = [], []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n            actuals.extend(labels.cpu().numpy())\n\n    print(f\"\\n{name} Accuracy: {accuracy_score(actuals, preds):.4f}\")\n    print(classification_report(actuals, preds))\n\n# Evaluasi kedua model\nevaluate(model_cased, val_loader_cased, name=\"BERT Cased\")\nevaluate(model_uncased, val_loader_uncased, name=\"BERT Uncased\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-13T18:19:21.056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_cased.save_pretrained(\"bert_cased_finetuned_yelp\")\ntokenizer_cased.save_pretrained(\"bert_cased_finetuned_yelp\")\n\nmodel_uncased.save_pretrained(\"bert_uncased_finetuned_yelp\")\ntokenizer_uncased.save_pretrained(\"bert_uncased_finetuned_yelp\")\n\nprint(\"Model saved berhasil yayyy\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13355381,"sourceType":"datasetVersion","datasetId":8470856}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Library & Setup","metadata":{}},{"cell_type":"code","source":"!pip install -U \"transformers==4.40.2\" \"huggingface-hub==0.23.5\" -q\n\nimport os\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n\n# Matiin HuggingFace chat template warning (soalnya sempet ada error)\nos.environ[\"HF_HUB_DISABLE_CHAT_TEMPLATES\"] = \"1\"\n\n# Cek device sekarang\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:43:20.537745Z","iopub.execute_input":"2025-10-14T12:43:20.538322Z","iopub.status.idle":"2025-10-14T12:43:40.438343Z","shell.execute_reply.started":"2025-10-14T12:43:20.538297Z","shell.execute_reply":"2025-10-14T12:43:40.437634Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.40.2 which is incompatible.\ndiffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.5 which is incompatible.\npeft 0.16.0 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\ngradio 5.38.1 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.5 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mUsing device: cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/yelp-bert-dataset/data bert 2.parquet\")\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:43:49.993485Z","iopub.execute_input":"2025-10-14T12:43:49.994633Z","iopub.status.idle":"2025-10-14T12:43:50.557583Z","shell.execute_reply.started":"2025-10-14T12:43:49.994598Z","shell.execute_reply":"2025-10-14T12:43:50.556630Z"}},"outputs":[{"name":"stdout","text":"                                                text  sentiment\n0  If you decide to eat here, just be aware it is...          1\n1  A couple friends and I stopped by for some lat...          1\n2  Sometimes this food is very very good.  Unfort...          1\n3  After trying a few ramen places with crazy var...          1\n4  Great food. Terrible customer service. I've be...          1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df['sentiment'] = df['sentiment'].astype('category').cat.codes\n\n# Split train & validation set\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    df['text'].tolist(), df['sentiment'].tolist(), test_size=0.2, random_state=42\n)\n\nprint(f\"Total data: {len(df)} | Train: {len(train_texts)} | Validation: {len(val_texts)}\")\nprint(df['sentiment'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:43:53.811500Z","iopub.execute_input":"2025-10-14T12:43:53.812101Z","iopub.status.idle":"2025-10-14T12:43:53.852122Z","shell.execute_reply.started":"2025-10-14T12:43:53.812079Z","shell.execute_reply":"2025-10-14T12:43:53.851502Z"}},"outputs":[{"name":"stdout","text":"Total data: 60000 | Train: 48000 | Validation: 12000\nsentiment\n1    20000\n2    20000\n0    20000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Tokenizer Preparation (Cased & Uncased)","metadata":{}},{"cell_type":"code","source":"tokenizer_cased = BertTokenizer.from_pretrained('bert-base-cased')\ntokenizer_uncased = BertTokenizer.from_pretrained('bert-base-uncased')\n\nprint(\"Tokenizer loaded successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:43:56.413381Z","iopub.execute_input":"2025-10-14T12:43:56.414171Z","iopub.status.idle":"2025-10-14T12:44:01.554918Z","shell.execute_reply.started":"2025-10-14T12:43:56.414143Z","shell.execute_reply":"2025-10-14T12:44:01.554175Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e15ec3c2c234387a2d93d812e643938"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df2cb84febb0419fabdb1c61d76c998c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a5bda1b2fe0405e9b5fed359ff8839f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"459d61cd82d14972954c14df6e26bd14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea44528fd27471994e870751b8641d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"667dffeb004c4335b8c3f0e4eb54e8fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9b1ddbbd61b493595613e1e7129d1b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86d682bf3a854a799df33f201c237a1b"}},"metadata":{}},{"name":"stdout","text":"Tokenizer loaded successfully!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Dataset & DataLoader","metadata":{}},{"cell_type":"code","source":"class TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=256):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        sentiment = self.labels[idx]\n        enc = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': enc['input_ids'].flatten(),\n            'attention_mask': enc['attention_mask'].flatten(),\n            'labels': torch.tensor(sentiment, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:44:07.821401Z","iopub.execute_input":"2025-10-14T12:44:07.822067Z","iopub.status.idle":"2025-10-14T12:44:07.829394Z","shell.execute_reply.started":"2025-10-14T12:44:07.822033Z","shell.execute_reply":"2025-10-14T12:44:07.828413Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_data_cased = TextDataset(train_texts, train_labels, tokenizer_cased)\nval_data_cased = TextDataset(val_texts, val_labels, tokenizer_cased)\ntrain_data_uncased = TextDataset(train_texts, train_labels, tokenizer_uncased)\nval_data_uncased = TextDataset(val_texts, val_labels, tokenizer_uncased)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:44:10.718705Z","iopub.execute_input":"2025-10-14T12:44:10.719179Z","iopub.status.idle":"2025-10-14T12:44:10.723271Z","shell.execute_reply.started":"2025-10-14T12:44:10.719154Z","shell.execute_reply":"2025-10-14T12:44:10.722346Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# DataLoader\ntrain_loader_cased = DataLoader(train_data_cased, batch_size=32, shuffle=True)\nval_loader_cased = DataLoader(val_data_cased, batch_size=32, shuffle=False)\ntrain_loader_uncased = DataLoader(train_data_uncased, batch_size=32, shuffle=True)\nval_loader_uncased = DataLoader(val_data_uncased, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:44:13.051816Z","iopub.execute_input":"2025-10-14T12:44:13.052374Z","iopub.status.idle":"2025-10-14T12:44:13.056709Z","shell.execute_reply.started":"2025-10-14T12:44:13.052348Z","shell.execute_reply":"2025-10-14T12:44:13.055851Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Model Initialization (BERT Cased & Uncased)","metadata":{}},{"cell_type":"code","source":"# BERT Cased\nmodel_cased = BertForSequenceClassification.from_pretrained(\n    'bert-base-cased', num_labels=len(set(df['sentiment']))\n).to(device)\n\noptimizer_cased = AdamW(model_cased.parameters(), lr=3e-5)\nscheduler_cased = get_linear_schedule_with_warmup(\n    optimizer_cased, num_warmup_steps=0, num_training_steps=len(train_loader_cased)*3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:44:15.203690Z","iopub.execute_input":"2025-10-14T12:44:15.204139Z","iopub.status.idle":"2025-10-14T12:44:20.202703Z","shell.execute_reply.started":"2025-10-14T12:44:15.204114Z","shell.execute_reply":"2025-10-14T12:44:20.202126Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41d27599aff34f48822f02ff5c68ab5b"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# BERT Uncased\nmodel_uncased = BertForSequenceClassification.from_pretrained(\n    'bert-base-uncased', num_labels=len(set(df['sentiment']))\n).to(device)\n\noptimizer_uncased = AdamW(model_uncased.parameters(), lr=3e-5)\nscheduler_uncased = get_linear_schedule_with_warmup(\n    optimizer_uncased, num_warmup_steps=0, num_training_steps=len(train_loader_uncased)*3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:44:22.473113Z","iopub.execute_input":"2025-10-14T12:44:22.473493Z","iopub.status.idle":"2025-10-14T12:44:25.086064Z","shell.execute_reply.started":"2025-10-14T12:44:22.473469Z","shell.execute_reply":"2025-10-14T12:44:25.085417Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10534e87c65e449bb29db818abc2c384"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# BERT Cased","metadata":{}},{"cell_type":"markdown","source":"## Training BERT Cased","metadata":{}},{"cell_type":"code","source":"epochs = 4\n\n# BERT Cased\nfor epoch in range(epochs):\n    model_cased.train()\n    total_loss = 0\n    for batch in tqdm(train_loader_cased, desc=f\"[Cased] Epoch {epoch+1}\"):\n        optimizer_cased.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model_cased(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer_cased.step()\n        scheduler_cased.step()\n\n    print(f\"[Cased] Epoch {epoch+1} | Loss: {total_loss/len(train_loader_cased):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T12:44:29.543337Z","iopub.execute_input":"2025-10-14T12:44:29.543927Z","iopub.status.idle":"2025-10-14T13:59:03.777320Z","shell.execute_reply.started":"2025-10-14T12:44:29.543902Z","shell.execute_reply":"2025-10-14T13:59:03.776334Z"}},"outputs":[{"name":"stderr","text":"[Cased] Epoch 1: 100%|██████████| 1500/1500 [18:34<00:00,  1.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 1 | Loss: 0.5184\n","output_type":"stream"},{"name":"stderr","text":"[Cased] Epoch 2: 100%|██████████| 1500/1500 [18:35<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 2 | Loss: 0.3621\n","output_type":"stream"},{"name":"stderr","text":"[Cased] Epoch 3: 100%|██████████| 1500/1500 [18:41<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 3 | Loss: 0.2240\n","output_type":"stream"},{"name":"stderr","text":"[Cased] Epoch 4: 100%|██████████| 1500/1500 [18:42<00:00,  1.34it/s]","output_type":"stream"},{"name":"stdout","text":"[Cased] Epoch 4 | Loss: 0.1605\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Matrix Evaluation BERT Cased","metadata":{}},{"cell_type":"code","source":"def evaluate(model, loader, name=\"Model\"):\n    model.eval()\n    preds, actuals = [], []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n            actuals.extend(labels.cpu().numpy())\n\n    print(f\"\\n{name} Accuracy: {accuracy_score(actuals, preds):.4f}\")\n    print(classification_report(actuals, preds))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T13:59:03.778564Z","iopub.execute_input":"2025-10-14T13:59:03.778843Z","iopub.status.idle":"2025-10-14T13:59:03.785876Z","shell.execute_reply.started":"2025-10-14T13:59:03.778823Z","shell.execute_reply":"2025-10-14T13:59:03.784912Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"evaluate(model_cased, val_loader_cased, name=\"BERT Cased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T13:59:03.786714Z","iopub.execute_input":"2025-10-14T13:59:03.786928Z","iopub.status.idle":"2025-10-14T14:00:52.320614Z","shell.execute_reply.started":"2025-10-14T13:59:03.786912Z","shell.execute_reply":"2025-10-14T14:00:52.319595Z"}},"outputs":[{"name":"stdout","text":"\nBERT Cased Accuracy: 0.8120\n              precision    recall  f1-score   support\n\n           0       0.85      0.83      0.84      4023\n           1       0.71      0.74      0.73      3963\n           2       0.88      0.86      0.87      4014\n\n    accuracy                           0.81     12000\n   macro avg       0.81      0.81      0.81     12000\nweighted avg       0.81      0.81      0.81     12000\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Save Model BERT Cased","metadata":{}},{"cell_type":"code","source":"model_cased.save_pretrained(\"bert_cased_finetuned_yelp\")\ntokenizer_cased.save_pretrained(\"bert_cased_finetuned_yelp\")\n\nprint(\"Model berhasil save yayyy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T14:00:52.322278Z","iopub.execute_input":"2025-10-14T14:00:52.322745Z","iopub.status.idle":"2025-10-14T14:00:53.195749Z","shell.execute_reply.started":"2025-10-14T14:00:52.322724Z","shell.execute_reply":"2025-10-14T14:00:53.194994Z"}},"outputs":[{"name":"stdout","text":"Model berhasil save yayyy\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# BERT Uncased","metadata":{}},{"cell_type":"markdown","source":"## Training BERT Uncased","metadata":{}},{"cell_type":"code","source":"# BERT Uncased\nfor epoch in range(epochs):\n    model_uncased.train()\n    total_loss = 0\n    for batch in tqdm(train_loader_uncased, desc=f\"[Uncased] Epoch {epoch+1}\"):\n        optimizer_uncased.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        outputs = model_uncased(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        optimizer_uncased.step()\n        scheduler_uncased.step()\n\n    print(f\"[Uncased] Epoch {epoch+1} | Loss: {total_loss/len(train_loader_uncased):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T14:00:57.847733Z","iopub.execute_input":"2025-10-14T14:00:57.848419Z","iopub.status.idle":"2025-10-14T15:15:50.992221Z","shell.execute_reply.started":"2025-10-14T14:00:57.848393Z","shell.execute_reply":"2025-10-14T15:15:50.991331Z"}},"outputs":[{"name":"stderr","text":"[Uncased] Epoch 1: 100%|██████████| 1500/1500 [18:42<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Uncased] Epoch 1 | Loss: 0.5081\n","output_type":"stream"},{"name":"stderr","text":"[Uncased] Epoch 2: 100%|██████████| 1500/1500 [18:43<00:00,  1.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Uncased] Epoch 2 | Loss: 0.3556\n","output_type":"stream"},{"name":"stderr","text":"[Uncased] Epoch 3: 100%|██████████| 1500/1500 [18:43<00:00,  1.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Uncased] Epoch 3 | Loss: 0.2227\n","output_type":"stream"},{"name":"stderr","text":"[Uncased] Epoch 4: 100%|██████████| 1500/1500 [18:43<00:00,  1.33it/s]","output_type":"stream"},{"name":"stdout","text":"[Uncased] Epoch 4 | Loss: 0.1621\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Matrix Evaluation BERT Uncased","metadata":{}},{"cell_type":"code","source":"def evaluate(model, loader, name=\"Model\"):\n    model.eval()\n    preds, actuals = [], []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n            actuals.extend(labels.cpu().numpy())\n\n    print(f\"\\n{name} Accuracy: {accuracy_score(actuals, preds):.4f}\")\n    print(classification_report(actuals, preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T15:15:50.993672Z","iopub.execute_input":"2025-10-14T15:15:50.994035Z","iopub.status.idle":"2025-10-14T15:15:50.999623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate(model_uncased, val_loader_uncased, name=\"BERT Uncased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T15:15:51.007786Z","iopub.execute_input":"2025-10-14T15:15:51.008121Z","iopub.status.idle":"2025-10-14T15:17:43.722746Z"}},"outputs":[{"name":"stdout","text":"\nBERT Uncased Accuracy: 0.8159\n              precision    recall  f1-score   support\n\n           0       0.85      0.84      0.84      4023\n           1       0.72      0.73      0.73      3963\n           2       0.87      0.88      0.87      4014\n\n    accuracy                           0.82     12000\n   macro avg       0.82      0.82      0.82     12000\nweighted avg       0.82      0.82      0.82     12000\n\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Save Model BERT Uncased","metadata":{}},{"cell_type":"code","source":"model_uncased.save_pretrained(\"bert_uncased_finetuned_yelp\")\ntokenizer_uncased.save_pretrained(\"bert_uncased_finetuned_yelp\")\n\nprint(\"Model berhasil save yayyy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T15:17:45.891088Z","iopub.execute_input":"2025-10-14T15:17:45.891769Z","iopub.status.idle":"2025-10-14T15:17:47.164693Z"}},"outputs":[{"name":"stdout","text":"Model berhasil save yayyy\n","output_type":"stream"}],"execution_count":null}]}